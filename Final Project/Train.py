# -*- coding: utf-8 -*-
"""Mango_Leaf_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vJ8Wg0lx_FEfAPhM3axERjySL60trvMS
"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/

import zipfile

dataset_path = "/content/drive/MyDrive/CSE465/Mango"  # Make sure this matches the exact file name

print("‚úÖ Dataset extracted successfully!")

"""**DATASET AUGMENTATION**"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Set directories
original_data_dir = "/content/drive/MyDrive/CSE465/Mango"  # Folder with original images
augmented_data_dir = "/content/augmented_dataset"  # Folder for augmented images
os.makedirs(augmented_data_dir, exist_ok=True)

# Create an ImageDataGenerator for augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load original images and apply augmentation
batch_size = 32
num_augmented_images = 0

for class_name in os.listdir(original_data_dir):  # Loop through each category
    class_path = os.path.join(original_data_dir, class_name)
    save_path = os.path.join(augmented_data_dir, class_name)
    os.makedirs(save_path, exist_ok=True)

    for image in os.listdir(class_path):  # Loop through images
        img_path = os.path.join(class_path, image)
        img = tf.keras.preprocessing.image.load_img(img_path)
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        img_array = img_array.reshape((1,) + img_array.shape)

        # Generate 2 augmented images per original
        i = 0
        for batch in datagen.flow(img_array, batch_size=1, save_to_dir=save_path, save_prefix="aug", save_format="jpg"):
            i += 1
            num_augmented_images += 1
            if i >= 2:  # Change this number to control how many new images per original
                break

print(f"‚úÖ Data augmentation completed! Added {num_augmented_images} images.")

from google.colab import files
files.download('augmented_dataset.zip')



!zip -r augmented_dataset.zip augmented_dataset

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import ResNet50
from sklearn.model_selection import StratifiedKFold
import numpy as np
import os
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define paths
augmented_data_dir = '/content/augmented_dataset'  # Folder where augmented images are stored

# Get the list of all image files and corresponding labels
image_paths = []
image_labels = []

# Traverse the directory to get paths and labels
for label, class_name in enumerate(os.listdir(augmented_data_dir)):
    class_path = os.path.join(augmented_data_dir, class_name)
    if os.path.isdir(class_path):
        for image_name in os.listdir(class_path):
            image_paths.append(os.path.join(class_path, image_name))
            image_labels.append(class_name)  # Use class_name (string) as the label

# Convert to numpy arrays
image_paths = np.array(image_paths)
image_labels = np.array(image_labels)

# Create a DataFrame
df = pd.DataFrame({
    'image_path': image_paths,
    'label': image_labels
})

# Initialize ImageDataGenerator for rescaling
datagen = ImageDataGenerator(rescale=1./255)

# Initialize ResNet50 model with pre-trained weights
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze the base layers

# Create the model
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dense(len(os.listdir(augmented_data_dir)), activation='softmax')  # Adjust the number of classes dynamically
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Set up 5-fold cross-validation
kfold = StratifiedKFold(n_splits=5, shuffle=True)

accuracies = []
for train_index, val_index in kfold.split(df['image_path'], df['label']):
    # Split the data into training and validation sets based on indices
    train_df = df.iloc[train_index]
    val_df = df.iloc[val_index]

    # Create new ImageDataGenerators for the current fold
    train_generator = datagen.flow_from_dataframe(
        dataframe=train_df,
        x_col='image_path',
        y_col='label',
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=True
    )

    val_generator = datagen.flow_from_dataframe(
        dataframe=val_df,
        x_col='image_path',
        y_col='label',
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )

    # Train the model on

# Save the trained model
model.save("/content/drive/MyDrive/CSE465/model.h5")  # This will save the model to the specified path

from google.colab import files
files.download('my_model.h5')

!cp /content/drive/MyDrive/CSE465/model.h5 model.h5

from google.colab import files
files.download("model.h5")

import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Initialize image generators (NO AUGMENTATION here, just rescaling)
datagen = ImageDataGenerator(rescale=1./255)

# Number of classes (adjust this if needed)
num_classes = df['label'].nunique()

# One-hot encode labels
df['label_encoded'] = pd.Categorical(df['label']).codes

# Initialize Stratified K-Fold
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Store metrics
results = []

# Start cross-validation
for fold, (train_idx, val_idx) in enumerate(kfold.split(df['image_path'], df['label_encoded']), 1):
    print(f"\nüîÅ Training Fold {fold}/5")

    train_df = df.iloc[train_idx]
    val_df = df.iloc[val_idx]

    train_gen = datagen.flow_from_dataframe(
        train_df,
        x_col='image_path',
        y_col='label',
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=True
    )

    val_gen = datagen.flow_from_dataframe(
        val_df,
        x_col='image_path',
        y_col='label',
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )

    # Define simple CNN model
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        MaxPooling2D(2, 2),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    # Train model
    model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=5,
        verbose=1
    )

    # Predict on validation data
    val_gen.reset()
    y_true = val_df['label_encoded'].values
    y_pred_probs = model.predict(val_gen, verbose=0)
    y_pred = np.argmax(y_pred_probs, axis=1)

    # Calculate metrics
    acc = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)
    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)

    print(f"Fold {fold} - Acc: {acc:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}, F1: {f1:.4f}")

    results.append({
        'Fold': fold,
        'Accuracy': acc,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    })

# Convert to DataFrame for easy viewing
results_df = pd.DataFrame(results)
print("\nüìä Final Results Table:\n")
print(results_df)

# Step 6: Test Script

import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load the trained model
loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/CSE465/model.h5')  # Adjust the path if necessary

# Test the model on new images
test_image_path = "/content/drive/MyDrive/CSE465/Mango/Anthracnose/20211008_124249 (Custom).jpg"  # Path to the test image (replace with your test image path)
test_image = image.load_img(test_image_path, target_size=(224, 224))  # Resize to match model input size
test_image_array = image.img_to_array(test_image)  # Convert image to array
test_image_array = np.expand_dims(test_image_array, axis=0)  # Add batch dimension
test_image_array /= 255.0  # Rescale the image (same preprocessing used during training)

# Predict using the model
prediction = loaded_model.predict(test_image_array)  # Get predictions
predicted_class = np.argmax(prediction, axis=1)  # Get the class with the highest probability

# Display the result
print(f"Predicted class: {predicted_class[0]}")  # Print the predicted class

!ls /content/augmented_dataset

from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D

num_classes = df['label'].nunique()

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam


# Load pre-trained ResNet-50 model without the top (classification) layer
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of ResNet-50 (you can also choose to fine-tune some layers later)
base_model.trainable = False

# Add custom classification layers on top
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(num_classes, activation='softmax')(x)

# Final model
model = Model(inputs=base_model.input, outputs=x)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])