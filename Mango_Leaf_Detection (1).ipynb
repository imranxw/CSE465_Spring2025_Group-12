{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN62Vo0gY1Er",
        "outputId": "57e9e199-eeb3-4dfb-ef9c-31d77c9a8808"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/\n",
        "\n"
      ],
      "metadata": {
        "id": "VjTxtZ--kAzz",
        "outputId": "4fb418b2-c2f9-4164-f5b6-70ac9d607ce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/CSE465/Mango\"  # Make sure this matches the exact file name\n",
        "\n",
        "print(\"✅ Dataset extracted successfully!\")\n"
      ],
      "metadata": {
        "id": "y3eN5a_jj3_4",
        "outputId": "be114e05-e8da-4501-e17e-e58ea16ad1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths\n",
        "augmented_data_dir = '/content/augmented_dataset'  # Folder where augmented images are stored\n",
        "\n",
        "# Get the list of all image files and corresponding labels\n",
        "image_paths = []\n",
        "image_labels = []\n",
        "\n",
        "# Traverse the directory to get paths and labels\n",
        "for label, class_name in enumerate(os.listdir(augmented_data_dir)):\n",
        "    class_path = os.path.join(augmented_data_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_paths.append(os.path.join(class_path, image_name))\n",
        "            image_labels.append(class_name)  # Use class_name (string) as the label\n",
        "\n",
        "# Convert to numpy arrays\n",
        "image_paths = np.array(image_paths)\n",
        "image_labels = np.array(image_labels)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'label': image_labels\n",
        "})\n",
        "\n",
        "# Initialize ImageDataGenerator for rescaling\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Initialize ResNet50 model with pre-trained weights\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the base layers\n",
        "\n",
        "# Create the model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(len(os.listdir(augmented_data_dir)), activation='softmax')  # Adjust the number of classes dynamically\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up 5-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "accuracies = []\n",
        "for train_index, val_index in kfold.split(df['image_path'], df['label']):\n",
        "    # Split the data into training and validation sets based on indices\n",
        "    train_df = df.iloc[train_index]\n",
        "    val_df = df.iloc[val_index]\n",
        "\n",
        "    # Create new ImageDataGenerators for the current fold\n",
        "    train_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = datagen.flow_from_dataframe(\n",
        "        dataframe=val_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Train the model on\n"
      ],
      "metadata": {
        "id": "jk9IXApJne52",
        "outputId": "14e9f47b-1660-4d1f-db31-729642c79763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save(\"/content/drive/MyDrive/CSE465/model.h5\")  # This will save the model to the specified path\n"
      ],
      "metadata": {
        "id": "3yw4wZe5n2_c",
        "outputId": "3acd1c10-b8f5-493f-db1e-72f4df0c5027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Test Script\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/CSE465/model.h5')  # Adjust the path if necessary\n",
        "\n",
        "# Test the model on new images\n",
        "test_image_path = \"/content/drive/MyDrive/CSE465/Mango/Anthracnose/20211008_124249 (Custom).jpg\"  # Path to the test image (replace with your test image path)\n",
        "test_image = image.load_img(test_image_path, target_size=(224, 224))  # Resize to match model input size\n",
        "test_image_array = image.img_to_array(test_image)  # Convert image to array\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0)  # Add batch dimension\n",
        "test_image_array /= 255.0  # Rescale the image (same preprocessing used during training)\n",
        "\n",
        "# Predict using the model\n",
        "prediction = loaded_model.predict(test_image_array)  # Get predictions\n",
        "predicted_class = np.argmax(prediction, axis=1)  # Get the class with the highest probability\n",
        "\n",
        "# Display the result\n",
        "print(f\"Predicted class: {predicted_class[0]}\")  # Print the predicted class\n"
      ],
      "metadata": {
        "id": "IpdN4QwUofKc",
        "outputId": "2974ad3f-e32b-46ad-a86d-0ddc2e45a20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Predicted class: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/augmented_dataset\n"
      ],
      "metadata": {
        "id": "QrKD9_Xfl6Ej",
        "outputId": "41a42ed2-3c60-4371-c7d1-db8e2821a42e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Anthracnose\t    'Cutting Weevil'  'Gall Midge'  'Powdery Mildew'\n",
            "'Bacterial Canker'  'Die Back'\t       Healthy\t    'Sooty Mould'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Initialize 5-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(df['image_path'], df['label']), 1):\n",
        "    print(f\"\\nTraining Fold {fold}/5...\")\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    train_df = df.iloc[train_index]\n",
        "    val_df = df.iloc[val_index]\n",
        "\n",
        "    # Create training data generator\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',  # Categorical because it's multi-class classification\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # Create validation data generator\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "LQEVAhaUE4Xj",
        "outputId": "ee904c4e-b6e5-40f5-f621-9d5465e6f38d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 1/5...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "If class_mode=\"categorical\", y_col=\"label\" column values must be type string, list or tuple.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-749d219a5b20>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create training data generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     train_generator = train_datagen.flow_from_dataframe(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m             )\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         return DataFrameIterator(\n\u001b[0m\u001b[1;32m   1209\u001b[0m             \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;31m# check that inputs match the required class_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         if (\n\u001b[1;32m    753\u001b[0m             \u001b[0mvalidate_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    842\u001b[0m                     \u001b[0;34m'If class_mode=\"{}\", y_col=\"{}\" column '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m                     \"values must be type string, list or tuple.\".format(\n",
            "\u001b[0;31mTypeError\u001b[0m: If class_mode=\"categorical\", y_col=\"label\" column values must be type string, list or tuple."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean label column by stripping extra spaces and converting to strings\n",
        "df['label'] = df['label'].str.strip().astype(str)\n",
        "\n",
        "# Check for any remaining null or incorrect values\n",
        "print(df['label'].isnull().sum())  # Should be 0\n",
        "print(df['label'].head())  # Check the first few labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NJF_upbDFaSD",
        "outputId": "cec10981-7bc6-4ba6-f596-75b8c7556edc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can only use .str accessor with string values!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9caebb796c5d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Clean label column by stripping extra spaces and converting to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check for any remaining null or incorrect values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ImageDataGenerator for rescaling\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize the image data to [0, 1] range\n",
        "    rotation_range=20,      # Rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Shift width by 20%\n",
        "    height_shift_range=0.2, # Shift height by 20%\n",
        "    shear_range=0.2,        # Shear transformation\n",
        "    zoom_range=0.2,         # Random zoom\n",
        "    horizontal_flip=True,   # Flip images horizontally\n",
        "    fill_mode='nearest'     # Fill missing pixels\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)  # Just rescale for validation\n",
        "\n",
        "# Initialize 5-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kfold.split(df['image_path'], df['label']), 1):\n",
        "    print(f\"\\nTraining Fold {fold}/5...\")\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    train_df = df.iloc[train_index]\n",
        "    val_df = df.iloc[val_index]\n",
        "\n",
        "    # Create training data generator\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),  # Resize images to match the model input size\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True  # Shuffle data for each epoch\n",
        "    )\n",
        "\n",
        "    # Create validation data generator\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False  # No shuffle for validation\n",
        "    )\n",
        "\n",
        "    # Now train the model using train_generator and val_generator\n",
        "    # (Assuming you have already defined and compiled your model earlier)\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(train_generator),\n",
        "        epochs=5,  # Change this based on your needs\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(val_generator)\n",
        "    )\n",
        "\n",
        "    # Save the model after each fold (optional)\n",
        "    model.save(f\"/content/drive/MyDrive/CSE465/model_fold_{fold}.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39iKXL-MF5HM",
        "outputId": "bff3f852-202c-41f4-ac8c-29d174276cf6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 1/5...\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m792s\u001b[0m 8s/step - accuracy: 0.1573 - loss: 2.1268 - val_accuracy: 0.2670 - val_loss: 1.9197\n",
            "Epoch 2/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m782s\u001b[0m 8s/step - accuracy: 0.2241 - loss: 1.9486 - val_accuracy: 0.2927 - val_loss: 1.8312\n",
            "Epoch 3/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 8s/step - accuracy: 0.2369 - loss: 1.9056 - val_accuracy: 0.3196 - val_loss: 1.7973\n",
            "Epoch 4/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 8s/step - accuracy: 0.2592 - loss: 1.8460 - val_accuracy: 0.3530 - val_loss: 1.7441\n",
            "Epoch 5/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 8s/step - accuracy: 0.2689 - loss: 1.8275 - val_accuracy: 0.3517 - val_loss: 1.7081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 2/5...\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 8s/step - accuracy: 0.2868 - loss: 1.8149 - val_accuracy: 0.3543 - val_loss: 1.6942\n",
            "Epoch 2/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 8s/step - accuracy: 0.3144 - loss: 1.7704 - val_accuracy: 0.2965 - val_loss: 1.6599\n",
            "Epoch 3/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m821s\u001b[0m 8s/step - accuracy: 0.2957 - loss: 1.7818 - val_accuracy: 0.3607 - val_loss: 1.6481\n",
            "Epoch 4/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 8s/step - accuracy: 0.2946 - loss: 1.7520 - val_accuracy: 0.3453 - val_loss: 1.6990\n",
            "Epoch 5/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 8s/step - accuracy: 0.3099 - loss: 1.7326 - val_accuracy: 0.3838 - val_loss: 1.6044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 3/5...\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 8s/step - accuracy: 0.3250 - loss: 1.7075 - val_accuracy: 0.3941 - val_loss: 1.5976\n",
            "Epoch 2/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m762s\u001b[0m 8s/step - accuracy: 0.3317 - loss: 1.6927 - val_accuracy: 0.4146 - val_loss: 1.5913\n",
            "Epoch 3/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 8s/step - accuracy: 0.3340 - loss: 1.6845 - val_accuracy: 0.3864 - val_loss: 1.6210\n",
            "Epoch 4/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 8s/step - accuracy: 0.3657 - loss: 1.6637 - val_accuracy: 0.4018 - val_loss: 1.5799\n",
            "Epoch 5/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 8s/step - accuracy: 0.3605 - loss: 1.6598 - val_accuracy: 0.3787 - val_loss: 1.5658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 4/5...\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 8s/step - accuracy: 0.3592 - loss: 1.6547 - val_accuracy: 0.3915 - val_loss: 1.5740\n",
            "Epoch 2/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 8s/step - accuracy: 0.3640 - loss: 1.6139 - val_accuracy: 0.4519 - val_loss: 1.5289\n",
            "Epoch 3/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 8s/step - accuracy: 0.3640 - loss: 1.6639 - val_accuracy: 0.4275 - val_loss: 1.4929\n",
            "Epoch 4/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 8s/step - accuracy: 0.3909 - loss: 1.6181 - val_accuracy: 0.4801 - val_loss: 1.4884\n",
            "Epoch 5/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 8s/step - accuracy: 0.3858 - loss: 1.6202 - val_accuracy: 0.4480 - val_loss: 1.4954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 5/5...\n",
            "Found 3116 validated image filenames belonging to 8 classes.\n",
            "Found 779 validated image filenames belonging to 8 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 8s/step - accuracy: 0.4113 - loss: 1.5960 - val_accuracy: 0.4454 - val_loss: 1.5226\n",
            "Epoch 2/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 8s/step - accuracy: 0.3905 - loss: 1.6208 - val_accuracy: 0.4724 - val_loss: 1.4808\n",
            "Epoch 3/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 8s/step - accuracy: 0.3833 - loss: 1.6020 - val_accuracy: 0.4262 - val_loss: 1.4985\n",
            "Epoch 4/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 8s/step - accuracy: 0.4153 - loss: 1.5453 - val_accuracy: 0.5109 - val_loss: 1.4389\n",
            "Epoch 5/5\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 8s/step - accuracy: 0.4196 - loss: 1.5571 - val_accuracy: 0.4223 - val_loss: 1.5427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'label' column to string type first\n",
        "df['label'] = df['label'].astype(str)\n",
        "\n",
        "# Now clean the label column\n",
        "df['label'] = df['label'].str.strip()\n",
        "\n",
        "# Check for any null or incorrect values\n",
        "print(df['label'].isnull().sum())  # Should be 0\n",
        "print(df['label'].head())  # Check the first few labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnLW28jjFqSp",
        "outputId": "e8d7b683-f884-474e-8570-c15424b69d0c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: label, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the type of the 'label' column\n",
        "print(df['label'].dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unm3dptkFmnu",
        "outputId": "87e97b68-b421-4059-f525-df7834733e46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "Hq82paMOr2pz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/imranxw/CSE465_Spring2025_Group-12.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ9ssaxjswza",
        "outputId": "124446cd-ad9d-486e-d807-1ef1cc890668"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSE465_Spring2025_Group-12'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), 323.29 KiB | 1.78 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/model_final.keras /content/CSE465_Spring2025_Group-12/\n",
        "!mv /content/your_script.py /content/CSE465_Spring2025_Group-12/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXAjO2uutHX2",
        "outputId": "47f91dcf-ba07-4799-e66a-e942ec455e2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/model_final.keras': No such file or directory\n",
            "mv: cannot stat '/content/your_script.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CSE465_Spring2025_Group-12\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr7Eum2AtOfQ",
        "outputId": "6413730a-0d39-4a2b-99f9-68561a515487"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSE465_Spring2025_Group-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "Q0PJazHLteix"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"imranxw\"\n"
      ],
      "metadata": {
        "id": "TrTq19QUuGTr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config user.name \"imranxw\"\n",
        "!git config user.email \"imran.khan05@northsouth.edu\"\n"
      ],
      "metadata": {
        "id": "mPcBiOk5ub7H"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Added trained model and evaluation scripts\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zjvbqvwthdh",
        "outputId": "c1427757-3991-431a-b995-13be14639c5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr6nEBJItlcv",
        "outputId": "c26988a3-2dcb-4715-f60a-f08edc188e8a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kd6SPZUu1Uj",
        "outputId": "23013272-f5af-4c79-a14e-32a8d242954e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBAaLBpSwsVi",
        "outputId": "a15a1100-4bca-4cde-d4af-5b9f3fb70c9f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome_To_Colab.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n"
      ],
      "metadata": {
        "id": "c2n6I-Igw4N8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Added trained model and evaluation scripts\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc4WkTV4w7g3",
        "outputId": "59d31b1b-8d9c-4f17-9930-59ce08dcfd11"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiPYqj4OxHh0",
        "outputId": "8e950eab-94cd-4162-b96d-7562158d948f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  .git  Welcome_To_Colab.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add model.h5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgbUsN6JxKGY",
        "outputId": "e08c1d0f-3432-4b9b-8dce-63075ba8e312"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: pathspec 'model.h5' did not match any files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plrKc-kExo-o",
        "outputId": "2977750b-3250-44fb-9b35-e4c857f41438"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add model.h5\n",
        "!git commit -m \"Added trained model\"\n",
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N8lnuMlx7dY",
        "outputId": "0a233ca2-165c-4157-cb33-13752156f004"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 7afb6a3] Added trained model\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 model.h5\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du6QHykWylAe",
        "outputId": "40e936e3-1d5a-4c9f-f671-c2be2f6c3af5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.keras')\n"
      ],
      "metadata": {
        "id": "GqJgQqXby7EC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuY2Nuz2zJZU",
        "outputId": "7491d8a3-ccdb-4e5e-c78f-ef0728c3e4ea"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CSE465_Spring2025_Group-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNOLisLRzMoW",
        "outputId": "77e0a0e6-e89c-40bd-dcea-ac46bc6e6577"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.h5  model.keras  Welcome_To_Colab.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Set directories\n",
        "original_data_dir = \"/content/drive/MyDrive/CSE465/Mango\"  # Folder with original images\n",
        "augmented_data_dir = \"/content/augmented_dataset\"  # Folder for augmented images\n",
        "os.makedirs(augmented_data_dir, exist_ok=True)\n",
        "\n",
        "# Create an ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,      # Rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Shift width by 20%\n",
        "    height_shift_range=0.2, # Shift height by 20%\n",
        "    shear_range=0.2,        # Shear transformation\n",
        "    zoom_range=0.2,         # Random zoom\n",
        "    horizontal_flip=True,   # Flip images horizontally\n",
        "    fill_mode='nearest'     # Fill missing pixels\n",
        ")\n",
        "\n",
        "# Load original images and apply augmentation\n",
        "batch_size = 32  # Number of images to process at a time\n",
        "num_augmented_images = 0\n",
        "\n",
        "for class_name in os.listdir(original_data_dir):  # Loop through each category\n",
        "    class_path = os.path.join(original_data_dir, class_name)\n",
        "    save_path = os.path.join(augmented_data_dir, class_name)\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    for image in os.listdir(class_path):  # Loop through images\n",
        "        img_path = os.path.join(class_path, image)\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = img_array.reshape((1,) + img_array.shape)  # Reshape for generator\n",
        "\n",
        "        # Generate new images and save\n",
        "        i = 0\n",
        "        for batch in datagen.flow(img_array, batch_size=1, save_to_dir=save_path, save_prefix=\"aug\", save_format=\"jpg\"):\n",
        "            i += 1\n",
        "            num_augmented_images += 1\n",
        "            if i >= 1:  # Generate 1 new image per original image (adjust for 30% increase)\n",
        "                break\n",
        "\n",
        "print(f\"✅ Data augmentation completed! Added {num_augmented_images} images.\")\n"
      ],
      "metadata": {
        "id": "rQNPRkwIlV-7",
        "outputId": "2fea9ba0-cd51-445e-dc02-8aafbd5212f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data augmentation completed! Added 4000 images.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}